{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Econometric Analysis: Impact of Tap Water (FHTC) on Health (Diarrhoea)\n",
        "\n",
        "This notebook runs a Fixed Effects Panel Regression to measure the impact of Functional Household Tap Connection (FHTC) coverage on diarrhoea cases.\n",
        "\n",
        "**Robust Version with Strict Data Cleaning:**\n",
        "1. Load and clean data (force numeric, drop missing/zeros)\n",
        "2. Engineer features (log transformation, bias detection)\n",
        "3. Run diagnostics to verify data quality\n",
        "4. Run two panel regressions with error handling\n",
        "5. Compare results to detect data inflation bias\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ linearmodels imported successfully\n",
            "✓ Config imported successfully\n",
            "✓ Libraries imported successfully\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Econometric libraries\n",
        "try:\n",
        "    from linearmodels import PanelOLS\n",
        "    print(\"✓ linearmodels imported successfully\")\n",
        "except ImportError:\n",
        "    print(\"❌ Error: linearmodels not installed\")\n",
        "    print(\"  Install with: pip install linearmodels\")\n",
        "    PanelOLS = None\n",
        "\n",
        "# Add parent directory to path for config imports\n",
        "sys.path.insert(0, str(Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()))\n",
        "\n",
        "try:\n",
        "    from config import FILE_PATHS\n",
        "    print(\"✓ Config imported successfully\")\n",
        "except ImportError:\n",
        "    FILE_PATHS = {\n",
        "        \"data\": {\n",
        "            \"raw\": \"data/raw\",\n",
        "            \"processed\": \"data/processed\"\n",
        "        }\n",
        "    }\n",
        "    print(\"⚠ Using fallback paths\")\n",
        "\n",
        "print(\"✓ Libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load & Clean\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading panel data from: c:\\JMM\\Project for Cursor\\data\\processed\\final_panel_2019.csv\n",
            "❌ Error: File not found at c:\\JMM\\Project for Cursor\\data\\processed\\final_panel_2019.csv\n",
            "Please run notebooks/03_Data_Preparation_2019.ipynb first to create the panel data\n"
          ]
        }
      ],
      "source": [
        "# Load data/processed/final_panel_2019.csv\n",
        "data_file = Path(FILE_PATHS[\"data\"][\"processed\"]) / \"final_panel_2019.csv\"\n",
        "print(f\"Loading panel data from: {data_file}\")\n",
        "\n",
        "try:\n",
        "    df = pd.read_csv(data_file)\n",
        "    print(f\"✓ Data loaded: {df.shape[0]:,} rows, {df.shape[1]} columns\")\n",
        "    print(f\"  Columns: {list(df.columns)}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"❌ Error: File not found at {data_file}\")\n",
        "    print(\"Please run notebooks/03_Data_Preparation_2019.ipynb first to create the panel data\")\n",
        "    df = None\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error loading data: {e}\")\n",
        "    df = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Force Numeric: Convert Cases and FHTC_Coverage to numeric using pd.to_numeric(..., errors='coerce')\n",
        "if df is not None:\n",
        "    print(\"\\nCleaning data...\")\n",
        "    print(f\"  Original shape: {df.shape}\")\n",
        "    \n",
        "    # Find Cases column\n",
        "    cases_col = None\n",
        "    for col in df.columns:\n",
        "        if 'Cases' in str(col) and 'Log' not in str(col):\n",
        "            cases_col = col\n",
        "            break\n",
        "    \n",
        "    # Find FHTC_Coverage column\n",
        "    coverage_col = None\n",
        "    for col in df.columns:\n",
        "        if 'FHTC' in str(col) or ('Coverage' in str(col) and 'FHTC' not in str(col)):\n",
        "            coverage_col = col\n",
        "            break\n",
        "    \n",
        "    if cases_col and coverage_col:\n",
        "        # Force numeric conversion\n",
        "        df[cases_col] = pd.to_numeric(df[cases_col], errors='coerce')\n",
        "        df[coverage_col] = pd.to_numeric(df[coverage_col], errors='coerce')\n",
        "        print(f\"  ✓ Converted {cases_col} and {coverage_col} to numeric\")\n",
        "        \n",
        "        # Drop Missing: Drop any rows where Cases or FHTC_Coverage is NaN\n",
        "        before_drop = len(df)\n",
        "        df = df.dropna(subset=[cases_col, coverage_col])\n",
        "        after_drop = len(df)\n",
        "        print(f\"  ✓ Dropped {before_drop - after_drop} rows with missing values\")\n",
        "        \n",
        "        # Drop Zeros: Filter out rows where Cases == 0 (since we are taking Logs)\n",
        "        before_zero = len(df)\n",
        "        df = df[df[cases_col] > 0]\n",
        "        after_zero = len(df)\n",
        "        print(f\"  ✓ Dropped {before_zero - after_zero} rows where Cases == 0\")\n",
        "        \n",
        "        # Convert Date to datetime\n",
        "        date_col = None\n",
        "        for col in ['Date', 'date', 'DATE']:\n",
        "            if col in df.columns:\n",
        "                date_col = col\n",
        "                break\n",
        "        \n",
        "        if date_col:\n",
        "            df['Date'] = pd.to_datetime(df[date_col], errors='coerce')\n",
        "        elif 'Month' in df.columns and 'Year' in df.columns:\n",
        "            month_map = {\n",
        "                'January': 1, 'February': 2, 'March': 3, 'April': 4,\n",
        "                'May': 5, 'June': 6, 'July': 7, 'August': 8,\n",
        "                'September': 9, 'October': 10, 'November': 11, 'December': 12\n",
        "            }\n",
        "            df['Month_Num'] = df['Month'].map(month_map)\n",
        "            df['Date'] = pd.to_datetime(df[['Year', 'Month_Num']].assign(day=1))\n",
        "            print(f\"  ✓ Created Date from Month and Year\")\n",
        "        \n",
        "        # Index: Set MultiIndex to ['District_Name', 'Date']\n",
        "        if 'District_Name' in df.columns and 'Date' in df.columns:\n",
        "            df = df.reset_index(drop=True)\n",
        "            df = df.set_index(['District_Name', 'Date'])\n",
        "            print(f\"  ✓ Set panel index: ['District_Name', 'Date']\")\n",
        "            print(f\"  Final shape: {df.shape}\")\n",
        "        else:\n",
        "            print(f\"  ❌ Error: Required columns for panel structure not found\")\n",
        "            df = None\n",
        "    else:\n",
        "        print(f\"  ❌ Error: Could not find Cases or FHTC_Coverage columns\")\n",
        "        print(f\"    Available columns: {list(df.columns)}\")\n",
        "        df = None\n",
        "else:\n",
        "    print(\"❌ Cannot clean: Data not loaded\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Feature Engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❌ Cannot create features: Data not loaded\n"
          ]
        }
      ],
      "source": [
        "# Create Log_Cases = np.log(Cases)\n",
        "if df is not None:\n",
        "    # Find Cases column\n",
        "    cases_col = None\n",
        "    for col in df.columns:\n",
        "        if 'Cases' in str(col) and 'Log' not in str(col):\n",
        "            cases_col = col\n",
        "            break\n",
        "    \n",
        "    # Find FHTC_Coverage column\n",
        "    coverage_col = None\n",
        "    for col in df.columns:\n",
        "        if 'FHTC' in str(col) or ('Coverage' in str(col) and 'FHTC' not in str(col)):\n",
        "            coverage_col = col\n",
        "            break\n",
        "    \n",
        "    if cases_col and coverage_col:\n",
        "        # Create Log_Cases = np.log(Cases)\n",
        "        df['Log_Cases'] = np.log(df[cases_col])\n",
        "        print(f\"✓ Created Log_Cases = log({cases_col})\")\n",
        "        print(f\"  Cases range: {df[cases_col].min():.0f} to {df[cases_col].max():.0f}\")\n",
        "        print(f\"  Log_Cases range: {df['Log_Cases'].min():.2f} to {df['Log_Cases'].max():.2f}\")\n",
        "        \n",
        "        # Create suspicious_flag (Change > 10%)\n",
        "        df = df.sort_index()\n",
        "        df['FHTC_Change'] = df.groupby(level='District_Name')[coverage_col].diff()\n",
        "        df['suspicious_flag'] = df['FHTC_Change'] > 10.0\n",
        "        print(f\"✓ Created suspicious_flag (coverage jump > 10%)\")\n",
        "        print(f\"  Suspicious observations: {df['suspicious_flag'].sum():,} ({df['suspicious_flag'].mean()*100:.1f}%)\")\n",
        "    else:\n",
        "        print(f\"❌ Error: Required columns not found\")\n",
        "        df = None\n",
        "else:\n",
        "    print(\"❌ Cannot create features: Data not loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❌ Cannot detect bias: Data not loaded\n"
          ]
        }
      ],
      "source": [
        "## Step 3: Diagnostics (Crucial)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Print df.info() to show data types\n",
        "# Print df.describe() to show min/max values\n",
        "# Check if the dataset is empty after cleaning. If empty, stop and print an error.\n",
        "if df is not None:\n",
        "    print(\"Data Diagnostics:\")\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"DATA INFO (Data Types)\")\n",
        "    print(f\"{'='*80}\")\n",
        "    df.info()\n",
        "    \n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"DATA DESCRIBE (Min/Max Values)\")\n",
        "    print(f\"{'='*80}\")\n",
        "    display(df.describe())\n",
        "    \n",
        "    # Check if the dataset is empty after cleaning\n",
        "    if len(df) == 0:\n",
        "        print(f\"\\n❌ ERROR: Dataset is empty after cleaning!\")\n",
        "        print(\"  Cannot proceed with analysis.\")\n",
        "        df = None\n",
        "    else:\n",
        "        print(f\"\\n✓ Dataset is not empty: {len(df):,} rows\")\n",
        "        print(f\"  Unique districts: {df.index.get_level_values('District_Name').nunique()}\")\n",
        "        print(f\"  Date range: {df.index.get_level_values('Date').min()} to {df.index.get_level_values('Date').max()}\")\n",
        "else:\n",
        "    print(\"❌ Cannot run diagnostics: Data not loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❌ Cannot run Model A: Data not loaded or linearmodels not available\n"
          ]
        }
      ],
      "source": [
        "## Step 4: Run Models (With Error Handling)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model A: Run on full data. If it fails, print the specific Python error message.\n",
        "if df is not None and PanelOLS is not None:\n",
        "    # Find columns\n",
        "    cases_col = None\n",
        "    for col in df.columns:\n",
        "        if 'Cases' in str(col) and 'Log' not in str(col):\n",
        "            cases_col = col\n",
        "            break\n",
        "    \n",
        "    coverage_col = None\n",
        "    for col in df.columns:\n",
        "        if 'FHTC' in str(col) or ('Coverage' in str(col) and 'FHTC' not in str(col)):\n",
        "            coverage_col = col\n",
        "            break\n",
        "    \n",
        "    if 'Log_Cases' in df.columns and coverage_col:\n",
        "        reg_data = df[['Log_Cases', coverage_col]].dropna()\n",
        "        \n",
        "        print(f\"Running Model A (Full Dataset)...\")\n",
        "        print(f\"  Observations: {len(reg_data):,}\")\n",
        "        print(f\"  Districts: {reg_data.index.get_level_values('District_Name').nunique()}\")\n",
        "        \n",
        "        try:\n",
        "            y = reg_data['Log_Cases']\n",
        "            X = reg_data[[coverage_col]]\n",
        "            \n",
        "            model_a = PanelOLS(\n",
        "                dependent=y,\n",
        "                exog=X,\n",
        "                entity_effects=True,\n",
        "                time_effects=True,\n",
        "                drop_absorbed=True\n",
        "            )\n",
        "            \n",
        "            results_a = model_a.fit(cov_type='clustered', cluster_entity=True)\n",
        "            \n",
        "            print(f\"\\n✓ Model A fitted successfully\")\n",
        "            print(f\"\\n{'='*80}\")\n",
        "            print(\"MODEL A SUMMARY (Full Dataset - 'Official' View)\")\n",
        "            print(f\"{'='*80}\")\n",
        "            print(results_a.summary)\n",
        "            \n",
        "            fhtc_coef_a = results_a.params[coverage_col]\n",
        "            fhtc_se_a = results_a.std_errors[coverage_col]\n",
        "            fhtc_pval_a = results_a.pvalues[coverage_col]\n",
        "            \n",
        "            print(f\"\\nKey Result:\")\n",
        "            print(f\"  FHTC_Coverage coefficient: {fhtc_coef_a:.6f}\")\n",
        "            print(f\"  Standard Error: {fhtc_se_a:.6f}\")\n",
        "            print(f\"  P-value: {fhtc_pval_a:.4f}\")\n",
        "            \n",
        "            model_a_success = True\n",
        "        except Exception as e:\n",
        "            print(f\"\\n❌ Model A failed with error:\")\n",
        "            print(f\"  {type(e).__name__}: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            results_a = None\n",
        "            fhtc_coef_a = None\n",
        "            fhtc_se_a = None\n",
        "            fhtc_pval_a = None\n",
        "            model_a_success = False\n",
        "    else:\n",
        "        print(\"❌ Error: Required columns not found\")\n",
        "        model_a_success = False\n",
        "        results_a = None\n",
        "        fhtc_coef_a = None\n",
        "else:\n",
        "    print(\"❌ Cannot run Model A: Data not loaded or linearmodels not available\")\n",
        "    model_a_success = False\n",
        "    results_a = None\n",
        "    fhtc_coef_a = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❌ Cannot run Model B: Data not loaded or linearmodels not available\n"
          ]
        }
      ],
      "source": [
        "# Model B: Run on filtered data. If it fails, print the error.\n",
        "if df is not None and PanelOLS is not None:\n",
        "    # Find columns\n",
        "    coverage_col = None\n",
        "    for col in df.columns:\n",
        "        if 'FHTC' in str(col) or ('Coverage' in str(col) and 'FHTC' not in str(col)):\n",
        "            coverage_col = col\n",
        "            break\n",
        "    \n",
        "    if 'suspicious_flag' in df.columns and 'Log_Cases' in df.columns and coverage_col:\n",
        "        df_clean = df[~df['suspicious_flag']].copy()\n",
        "        reg_data_clean = df_clean[['Log_Cases', coverage_col]].dropna()\n",
        "        \n",
        "        print(f\"\\nRunning Model B (Sanitized Dataset - Excluding Suspicious Spikes)...\")\n",
        "        print(f\"  Observations: {len(reg_data_clean):,}\")\n",
        "        print(f\"  Districts: {reg_data_clean.index.get_level_values('District_Name').nunique()}\")\n",
        "        print(f\"  Observations removed: {len(df) - len(df_clean):,}\")\n",
        "        \n",
        "        try:\n",
        "            y_clean = reg_data_clean['Log_Cases']\n",
        "            X_clean = reg_data_clean[[coverage_col]]\n",
        "            \n",
        "            model_b = PanelOLS(\n",
        "                dependent=y_clean,\n",
        "                exog=X_clean,\n",
        "                entity_effects=True,\n",
        "                time_effects=True,\n",
        "                drop_absorbed=True\n",
        "            )\n",
        "            \n",
        "            results_b = model_b.fit(cov_type='clustered', cluster_entity=True)\n",
        "            \n",
        "            print(f\"\\n✓ Model B fitted successfully\")\n",
        "            print(f\"\\n{'='*80}\")\n",
        "            print(\"MODEL B SUMMARY (Sanitized Dataset - 'Clean' View)\")\n",
        "            print(f\"{'='*80}\")\n",
        "            print(results_b.summary)\n",
        "            \n",
        "            fhtc_coef_b = results_b.params[coverage_col]\n",
        "            fhtc_se_b = results_b.std_errors[coverage_col]\n",
        "            fhtc_pval_b = results_b.pvalues[coverage_col]\n",
        "            \n",
        "            print(f\"\\nKey Result:\")\n",
        "            print(f\"  FHTC_Coverage coefficient: {fhtc_coef_b:.6f}\")\n",
        "            print(f\"  Standard Error: {fhtc_se_b:.6f}\")\n",
        "            print(f\"  P-value: {fhtc_pval_b:.4f}\")\n",
        "            \n",
        "            model_b_success = True\n",
        "        except Exception as e:\n",
        "            print(f\"\\n❌ Model B failed with error:\")\n",
        "            print(f\"  {type(e).__name__}: {str(e)}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            results_b = None\n",
        "            fhtc_coef_b = None\n",
        "            fhtc_se_b = None\n",
        "            fhtc_pval_b = None\n",
        "            model_b_success = False\n",
        "    else:\n",
        "        print(\"❌ Error: Required columns not found\")\n",
        "        model_b_success = False\n",
        "        results_b = None\n",
        "        fhtc_coef_b = None\n",
        "else:\n",
        "    print(\"❌ Cannot run Model B: Data not loaded or linearmodels not available\")\n",
        "    model_b_success = False\n",
        "    results_b = None\n",
        "    fhtc_coef_b = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "❌ Cannot compare: Models were not run\n"
          ]
        }
      ],
      "source": [
        "# Only compare if both models succeeded. Print the coefficients.\n",
        "if 'model_a_success' in locals() and 'model_b_success' in locals():\n",
        "    if model_a_success and model_b_success:\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(\"COMPARISON: FHTC_Coverage Coefficient\")\n",
        "        print(f\"{'='*80}\")\n",
        "        \n",
        "        comparison_df = pd.DataFrame({\n",
        "            'Model': ['Model A (Full Dataset)', 'Model B (Sanitized)'],\n",
        "            'Coefficient': [fhtc_coef_a, fhtc_coef_b],\n",
        "            'Std Error': [fhtc_se_a, fhtc_se_b],\n",
        "            'P-value': [fhtc_pval_a, fhtc_pval_b],\n",
        "            'Significant (5%)': [\n",
        "                'Yes' if fhtc_pval_a < 0.05 else 'No',\n",
        "                'Yes' if fhtc_pval_b < 0.05 else 'No'\n",
        "            ]\n",
        "        })\n",
        "        \n",
        "        display(comparison_df)\n",
        "        \n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(\"INTERPRETATION\")\n",
        "        print(f\"{'='*80}\")\n",
        "        \n",
        "        coef_diff = fhtc_coef_b - fhtc_coef_a\n",
        "        coef_diff_pct = (coef_diff / abs(fhtc_coef_a) * 100) if fhtc_coef_a != 0 else 0\n",
        "        \n",
        "        print(f\"\\nCoefficient Change:\")\n",
        "        print(f\"  Model A (Full):     {fhtc_coef_a:.6f}\")\n",
        "        print(f\"  Model B (Clean):    {fhtc_coef_b:.6f}\")\n",
        "        print(f\"  Difference:         {coef_diff:.6f} ({coef_diff_pct:+.1f}%)\")\n",
        "        \n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(\"THE VERDICT\")\n",
        "        print(f\"{'='*80}\")\n",
        "        \n",
        "        if fhtc_coef_a < 0 and fhtc_coef_b < 0:\n",
        "            if abs(fhtc_coef_b) > abs(fhtc_coef_a):\n",
        "                print(f\"\\n✓ EVIDENCE OF DATA INFLATION BIAS DETECTED\")\n",
        "                print(f\"Model B (Clean) has a STRONGER negative coefficient than Model A (Full).\")\n",
        "                print(f\"This suggests data inflation is masking the true health benefits.\")\n",
        "            else:\n",
        "                print(f\"\\n⚠ No clear evidence of data inflation bias\")\n",
        "        elif fhtc_coef_a > 0 and fhtc_coef_b < 0:\n",
        "            print(f\"\\n✓ STRONG EVIDENCE OF DATA INFLATION BIAS\")\n",
        "            print(f\"Model A shows positive coefficient (counterintuitive)\")\n",
        "            print(f\"Model B shows negative coefficient (expected)\")\n",
        "        else:\n",
        "            print(f\"\\nResults require careful interpretation\")\n",
        "        \n",
        "        print(f\"\\n{'='*80}\")\n",
        "    else:\n",
        "        print(f\"\\n❌ Cannot compare: One or both models failed\")\n",
        "        if not model_a_success:\n",
        "            print(f\"  Model A failed\")\n",
        "        if not model_b_success:\n",
        "            print(f\"  Model B failed\")\n",
        "else:\n",
        "    print(\"❌ Cannot compare: Models were not run\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This robust analysis compared two panel regression models with strict data cleaning:\n",
        "\n",
        "**Data Cleaning Steps:**\n",
        "- Force numeric conversion for Cases and FHTC_Coverage\n",
        "- Drop rows with missing values\n",
        "- Drop rows where Cases == 0 (required for log transformation)\n",
        "- Set proper panel structure with MultiIndex\n",
        "\n",
        "**Model A (Full Dataset - \"Official\" View):**\n",
        "- Uses all observations including suspicious spikes\n",
        "- Represents the \"official\" view that might include data inflation\n",
        "\n",
        "**Model B (Sanitized Dataset - \"Clean\" View):**\n",
        "- Excludes observations with suspicious coverage spikes (>10% month-on-month increase)\n",
        "- Represents a \"sanitized\" view that filters out potential data inflation\n",
        "\n",
        "**Key Finding:**\n",
        "If Model B shows a stronger negative coefficient than Model A, this provides evidence that data inflation is masking the true health benefits of tap water coverage.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
