{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Preparation: JJM and Health Data Merge\n",
        "\n",
        "This notebook prepares the final panel dataset by:\n",
        "1. Loading cleaned JJM data and Health data\n",
        "2. Standardizing district names using fuzzy matching\n",
        "3. Merging datasets on District_Name and Date\n",
        "4. Saving the final panel dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import difflib\n",
        "import re\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "# Add parent directory to path for config imports\n",
        "sys.path.insert(0, str(Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()))\n",
        "\n",
        "try:\n",
        "    from config import FILE_PATHS\n",
        "    print(\"✓ Config imported successfully\")\n",
        "except ImportError:\n",
        "    # Fallback paths if config not available\n",
        "    FILE_PATHS = {\n",
        "        \"data\": {\n",
        "            \"raw\": \"data/raw\",\n",
        "            \"processed\": \"data/processed\"\n",
        "        }\n",
        "    }\n",
        "    print(\"⚠ Using fallback paths\")\n",
        "\n",
        "print(\"✓ Libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Data\n",
        "\n",
        "Load the cleaned JJM data and Health data CSV files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load JJM cleaned data\n",
        "jjm_file = Path(FILE_PATHS[\"data\"][\"processed\"]) / \"jjm_cleaned.csv\"\n",
        "print(f\"Loading JJM data from: {jjm_file}\")\n",
        "\n",
        "try:\n",
        "    jjm_df = pd.read_csv(jjm_file)\n",
        "    print(f\"✓ JJM data loaded: {jjm_df.shape[0]} rows, {jjm_df.shape[1]} columns\")\n",
        "    print(f\"  Columns: {list(jjm_df.columns)}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    display(jjm_df.head())\n",
        "except FileNotFoundError:\n",
        "    print(f\"⚠ Error: File not found at {jjm_file}\")\n",
        "    print(\"Creating sample JJM data for demonstration...\")\n",
        "    jjm_df = pd.DataFrame({\n",
        "        'district_code': ['D001', 'D002', 'D003'],\n",
        "        'district_name': ['Kalaburagi', 'Mumbai', 'Delhi'],\n",
        "        'date': ['2024-01-01', '2024-01-01', '2024-01-01'],\n",
        "        'fhtc_coverage': [75.5, 85.2, 90.1]\n",
        "    })\n",
        "    print(f\"✓ Sample JJM data created: {jjm_df.shape}\")\n",
        "    display(jjm_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Health data\n",
        "health_file = Path(FILE_PATHS[\"data\"][\"raw\"]) / \"health_data.csv\"\n",
        "print(f\"Loading Health data from: {health_file}\")\n",
        "\n",
        "try:\n",
        "    health_df = pd.read_csv(health_file)\n",
        "    print(f\"✓ Health data loaded: {health_df.shape[0]} rows, {health_df.shape[1]} columns\")\n",
        "    print(f\"  Columns: {list(health_df.columns)}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    display(health_df.head())\n",
        "except FileNotFoundError:\n",
        "    print(f\"⚠ Error: File not found at {health_file}\")\n",
        "    print(\"Creating sample Health data for demonstration...\")\n",
        "    health_df = pd.DataFrame({\n",
        "        'District_Name': ['Gulbarga', 'Mumbai City', 'New Delhi'],\n",
        "        'Date': ['2024-01-01', '2024-01-01', '2024-01-01'],\n",
        "        'disease_cases': [120, 350, 280],\n",
        "        'mortality_rate': [2.5, 1.8, 1.2]\n",
        "    })\n",
        "    print(f\"✓ Sample Health data created: {health_df.shape}\")\n",
        "    display(health_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Fuzzy Matching Function\n",
        "\n",
        "Create a function to standardize district names using fuzzy matching. This handles variations like:\n",
        "- 'Kalaburagi' vs 'Gulbarga'\n",
        "- 'Mumbai' vs 'Mumbai City'\n",
        "- 'Delhi' vs 'New Delhi'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize_string(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Normalize a string for comparison by:\n",
        "    - Converting to lowercase\n",
        "    - Removing extra whitespace\n",
        "    - Removing special characters (keeping alphanumeric and spaces)\n",
        "    \n",
        "    Args:\n",
        "        text: Input string\n",
        "    \n",
        "    Returns:\n",
        "        Normalized string\n",
        "    \"\"\"\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = str(text)\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    # Remove special characters but keep alphanumeric and spaces\n",
        "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "def find_best_match(\n",
        "    target: str,\n",
        "    candidates: List[str],\n",
        "    threshold: float = 0.6,\n",
        "    use_normalization: bool = True\n",
        ") -> Tuple[str, float]:\n",
        "    \"\"\"\n",
        "    Find the best matching string from a list of candidates using fuzzy matching.\n",
        "    \n",
        "    Args:\n",
        "        target: The string to match\n",
        "        candidates: List of candidate strings\n",
        "        threshold: Minimum similarity ratio (0-1) to consider a match\n",
        "        use_normalization: Whether to normalize strings before matching\n",
        "    \n",
        "    Returns:\n",
        "        Tuple of (best_match, similarity_score)\n",
        "    \"\"\"\n",
        "    if not candidates or pd.isna(target):\n",
        "        return (target, 0.0)\n",
        "    \n",
        "    target_str = normalize_string(target) if use_normalization else str(target).lower()\n",
        "    \n",
        "    best_match = target\n",
        "    best_score = 0.0\n",
        "    \n",
        "    for candidate in candidates:\n",
        "        candidate_str = normalize_string(candidate) if use_normalization else str(candidate).lower()\n",
        "        \n",
        "        # Calculate similarity ratio using SequenceMatcher\n",
        "        similarity = difflib.SequenceMatcher(None, target_str, candidate_str).ratio()\n",
        "        \n",
        "        if similarity > best_score:\n",
        "            best_score = similarity\n",
        "            best_match = candidate\n",
        "    \n",
        "    # If best match is below threshold, return original\n",
        "    if best_score < threshold:\n",
        "        return (target, best_score)\n",
        "    \n",
        "    return (best_match, best_score)\n",
        "\n",
        "\n",
        "def standardize_district_names(\n",
        "    df: pd.DataFrame,\n",
        "    district_col: str,\n",
        "    reference_list: List[str] = None,\n",
        "    threshold: float = 0.6,\n",
        "    create_mapping: bool = True\n",
        ") -> Tuple[pd.DataFrame, Dict[str, str]]:\n",
        "    \"\"\"\n",
        "    Standardize district names in a dataframe using fuzzy matching.\n",
        "    \n",
        "    Args:\n",
        "        df: Input dataframe\n",
        "        district_col: Name of the district column\n",
        "        reference_list: List of standardized district names to match against.\n",
        "                       If None, uses unique values from the column itself.\n",
        "        threshold: Minimum similarity ratio for matching\n",
        "        create_mapping: Whether to return the mapping dictionary\n",
        "    \n",
        "    Returns:\n",
        "        Tuple of (dataframe with standardized names, mapping dictionary)\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    \n",
        "    # Get unique district names\n",
        "    unique_districts = df[district_col].unique().tolist()\n",
        "    \n",
        "    # Use reference list if provided, otherwise use the unique districts as reference\n",
        "    if reference_list is None:\n",
        "        reference_list = unique_districts.copy()\n",
        "    \n",
        "    # Create mapping dictionary\n",
        "    mapping = {}\n",
        "    \n",
        "    for district in unique_districts:\n",
        "        if pd.isna(district):\n",
        "            continue\n",
        "        \n",
        "        # Find best match in reference list\n",
        "        best_match, score = find_best_match(district, reference_list, threshold=threshold)\n",
        "        \n",
        "        if score >= threshold:\n",
        "            mapping[str(district)] = best_match\n",
        "        else:\n",
        "            # If no good match found, keep original\n",
        "            mapping[str(district)] = str(district)\n",
        "    \n",
        "    # Apply mapping\n",
        "    df[district_col] = df[district_col].map(mapping).fillna(df[district_col])\n",
        "    \n",
        "    if create_mapping:\n",
        "        return df, mapping\n",
        "    else:\n",
        "        return df\n",
        "\n",
        "\n",
        "print(\"✓ Fuzzy matching functions defined\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify district name columns\n",
        "# Check common column name variations\n",
        "jjm_district_col = None\n",
        "health_district_col = None\n",
        "\n",
        "# Common variations of district name columns\n",
        "district_col_variations = ['district_name', 'District_Name', 'district', 'District', \n",
        "                          'dist_name', 'Dist_Name', 'name', 'Name']\n",
        "\n",
        "for col in jjm_df.columns:\n",
        "    if col in district_col_variations or 'district' in col.lower():\n",
        "        jjm_district_col = col\n",
        "        break\n",
        "\n",
        "for col in health_df.columns:\n",
        "    if col in district_col_variations or 'district' in col.lower():\n",
        "        health_district_col = col\n",
        "        break\n",
        "\n",
        "print(f\"JJM district column: {jjm_district_col}\")\n",
        "print(f\"Health district column: {health_district_col}\")\n",
        "\n",
        "if jjm_district_col is None or health_district_col is None:\n",
        "    print(\"⚠ Warning: Could not auto-detect district columns. Using defaults.\")\n",
        "    if jjm_district_col is None:\n",
        "        jjm_district_col = 'district_name'\n",
        "        if jjm_district_col not in jjm_df.columns:\n",
        "            jjm_df[jjm_district_col] = jjm_df.iloc[:, 0]  # Use first column as fallback\n",
        "    \n",
        "    if health_district_col is None:\n",
        "        health_district_col = 'District_Name'\n",
        "        if health_district_col not in health_df.columns:\n",
        "            health_df[health_district_col] = health_df.iloc[:, 0]  # Use first column as fallback\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get unique district names from both datasets\n",
        "jjm_districts = jjm_df[jjm_district_col].dropna().unique().tolist()\n",
        "health_districts = health_df[health_district_col].dropna().unique().tolist()\n",
        "\n",
        "print(f\"Unique districts in JJM data: {len(jjm_districts)}\")\n",
        "print(f\"Unique districts in Health data: {len(health_districts)}\")\n",
        "print(f\"\\nJJM districts: {jjm_districts[:10]}\")  # Show first 10\n",
        "print(f\"Health districts: {health_districts[:10]}\")  # Show first 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a combined reference list for standardization\n",
        "# Use JJM districts as the primary reference (or combine both)\n",
        "reference_districts = list(set(jjm_districts + health_districts))\n",
        "print(f\"Total unique districts across both datasets: {len(reference_districts)}\")\n",
        "\n",
        "# Standardize district names in both datasets\n",
        "# Use JJM as the reference standard\n",
        "print(\"\\nStandardizing JJM district names...\")\n",
        "jjm_df_std, jjm_mapping = standardize_district_names(\n",
        "    jjm_df, \n",
        "    district_col=jjm_district_col,\n",
        "    reference_list=jjm_districts,  # Use JJM as reference\n",
        "    threshold=0.6\n",
        ")\n",
        "\n",
        "print(\"\\nStandardizing Health district names...\")\n",
        "health_df_std, health_mapping = standardize_district_names(\n",
        "    health_df,\n",
        "    district_col=health_district_col,\n",
        "    reference_list=jjm_districts,  # Match to JJM districts\n",
        "    threshold=0.6\n",
        ")\n",
        "\n",
        "print(f\"\\n✓ District name standardization complete\")\n",
        "print(f\"\\nJJM mapping examples:\")\n",
        "for orig, std in list(jjm_mapping.items())[:5]:\n",
        "    if orig != std:\n",
        "        print(f\"  {orig} -> {std}\")\n",
        "\n",
        "print(f\"\\nHealth mapping examples:\")\n",
        "for orig, std in list(health_mapping.items())[:5]:\n",
        "    if orig != std:\n",
        "        print(f\"  {orig} -> {std}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify standardization\n",
        "print(\"Standardized JJM districts:\")\n",
        "print(jjm_df_std[jjm_district_col].unique()[:10])\n",
        "\n",
        "print(\"\\nStandardized Health districts:\")\n",
        "print(health_df_std[health_district_col].unique()[:10])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Prepare Date Columns\n",
        "\n",
        "Ensure date columns are in the same format for merging.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Identify date columns\n",
        "jjm_date_col = None\n",
        "health_date_col = None\n",
        "\n",
        "date_col_variations = ['date', 'Date', 'period', 'Period', 'month', 'Month', \n",
        "                      'year', 'Year', 'reporting_date', 'Reporting_Date']\n",
        "\n",
        "for col in jjm_df_std.columns:\n",
        "    if col in date_col_variations or 'date' in col.lower():\n",
        "        jjm_date_col = col\n",
        "        break\n",
        "\n",
        "for col in health_df_std.columns:\n",
        "    if col in date_col_variations or 'date' in col.lower():\n",
        "        health_date_col = col\n",
        "        break\n",
        "\n",
        "print(f\"JJM date column: {jjm_date_col}\")\n",
        "print(f\"Health date column: {health_date_col}\")\n",
        "\n",
        "# Convert date columns to datetime\n",
        "if jjm_date_col:\n",
        "    jjm_df_std[jjm_date_col] = pd.to_datetime(jjm_df_std[jjm_date_col], errors='coerce')\n",
        "    print(f\"✓ JJM date column converted to datetime\")\n",
        "\n",
        "if health_date_col:\n",
        "    health_df_std[health_date_col] = pd.to_datetime(health_df_std[health_date_col], errors='coerce')\n",
        "    print(f\"✓ Health date column converted to datetime\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Merge Datasets\n",
        "\n",
        "Merge the standardized datasets on District_Name and Date.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure both datasets have the same column names for merging\n",
        "# Rename columns to standard names if needed\n",
        "merge_district_col = 'District_Name'\n",
        "merge_date_col = 'Date'\n",
        "\n",
        "# Rename columns for consistent merging\n",
        "if jjm_district_col != merge_district_col:\n",
        "    jjm_df_std = jjm_df_std.rename(columns={jjm_district_col: merge_district_col})\n",
        "    print(f\"✓ Renamed JJM district column to '{merge_district_col}'\")\n",
        "\n",
        "if health_district_col != merge_district_col:\n",
        "    health_df_std = health_df_std.rename(columns={health_district_col: merge_district_col})\n",
        "    print(f\"✓ Renamed Health district column to '{merge_district_col}'\")\n",
        "\n",
        "if jjm_date_col and jjm_date_col != merge_date_col:\n",
        "    jjm_df_std = jjm_df_std.rename(columns={jjm_date_col: merge_date_col})\n",
        "    print(f\"✓ Renamed JJM date column to '{merge_date_col}'\")\n",
        "\n",
        "if health_date_col and health_date_col != merge_date_col:\n",
        "    health_df_std = health_df_std.rename(columns={health_date_col: merge_date_col})\n",
        "    print(f\"✓ Renamed Health date column to '{merge_date_col}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for missing values in merge keys\n",
        "print(\"Missing values in merge keys:\")\n",
        "print(f\"JJM - District_Name: {jjm_df_std[merge_district_col].isna().sum()}\")\n",
        "print(f\"JJM - Date: {jjm_df_std[merge_date_col].isna().sum()}\")\n",
        "print(f\"Health - District_Name: {health_df_std[merge_district_col].isna().sum()}\")\n",
        "print(f\"Health - Date: {health_df_std[merge_date_col].isna().sum()}\")\n",
        "\n",
        "# Remove rows with missing merge keys\n",
        "jjm_df_std = jjm_df_std.dropna(subset=[merge_district_col, merge_date_col])\n",
        "health_df_std = health_df_std.dropna(subset=[merge_district_col, merge_date_col])\n",
        "\n",
        "print(f\"\\nAfter removing missing values:\")\n",
        "print(f\"JJM rows: {len(jjm_df_std)}\")\n",
        "print(f\"Health rows: {len(health_df_std)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Perform the merge\n",
        "print(\"Merging datasets...\")\n",
        "print(f\"JJM shape: {jjm_df_std.shape}\")\n",
        "print(f\"Health shape: {health_df_std.shape}\")\n",
        "\n",
        "# Merge on District_Name and Date\n",
        "merged_df = pd.merge(\n",
        "    jjm_df_std,\n",
        "    health_df_std,\n",
        "    on=[merge_district_col, merge_date_col],\n",
        "    how='outer',  # Use outer join to keep all records\n",
        "    suffixes=('_jjm', '_health'),\n",
        "    indicator=True  # Track merge source\n",
        ")\n",
        "\n",
        "print(f\"\\n✓ Merge complete!\")\n",
        "print(f\"Merged dataset shape: {merged_df.shape}\")\n",
        "print(f\"\\nMerge statistics:\")\n",
        "print(merged_df['_merge'].value_counts())\n",
        "\n",
        "# Display first few rows\n",
        "print(\"\\nFirst few rows of merged dataset:\")\n",
        "display(merged_df.head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for merge quality\n",
        "print(\"Merge Quality Check:\")\n",
        "print(f\"Total merged rows: {len(merged_df)}\")\n",
        "print(f\"Rows with both datasets: {len(merged_df[merged_df['_merge'] == 'both'])}\")\n",
        "print(f\"Rows only in JJM: {len(merged_df[merged_df['_merge'] == 'left_only'])}\")\n",
        "print(f\"Rows only in Health: {len(merged_df[merged_df['_merge'] == 'right_only'])}\")\n",
        "\n",
        "# Show districts that didn't match\n",
        "if len(merged_df[merged_df['_merge'] == 'left_only']) > 0:\n",
        "    unmatched_jjm = merged_df[merged_df['_merge'] == 'left_only'][merge_district_col].unique()\n",
        "    print(f\"\\nDistricts in JJM but not in Health: {len(unmatched_jjm)}\")\n",
        "    print(unmatched_jjm[:10])\n",
        "\n",
        "if len(merged_df[merged_df['_merge'] == 'right_only']) > 0:\n",
        "    unmatched_health = merged_df[merged_df['_merge'] == 'right_only'][merge_district_col].unique()\n",
        "    print(f\"\\nDistricts in Health but not in JJM: {len(unmatched_health)}\")\n",
        "    print(unmatched_health[:10])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Save Final Panel Dataset\n",
        "\n",
        "Save the merged panel dataset to the processed data directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove the merge indicator column before saving\n",
        "if '_merge' in merged_df.columns:\n",
        "    merged_df_final = merged_df.drop(columns=['_merge'])\n",
        "else:\n",
        "    merged_df_final = merged_df.copy()\n",
        "\n",
        "# Save to processed data directory\n",
        "output_file = Path(FILE_PATHS[\"data\"][\"processed\"]) / \"final_panel.csv\"\n",
        "output_file.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "merged_df_final.to_csv(output_file, index=False, encoding='utf-8')\n",
        "\n",
        "print(f\"✓ Final panel dataset saved to: {output_file}\")\n",
        "print(f\"  Shape: {merged_df_final.shape}\")\n",
        "print(f\"  Columns: {list(merged_df_final.columns)}\")\n",
        "print(f\"\\nDataset summary:\")\n",
        "print(merged_df_final.info())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display summary statistics\n",
        "print(\"\\nSummary Statistics:\")\n",
        "print(merged_df_final.describe())\n",
        "\n",
        "print(\"\\n✓ Data preparation complete!\")\n",
        "print(f\"\\nFinal panel dataset ready for analysis:\")\n",
        "print(f\"  - File: {output_file}\")\n",
        "print(f\"  - Rows: {len(merged_df_final):,}\")\n",
        "print(f\"  - Columns: {len(merged_df_final.columns)}\")\n",
        "print(f\"  - Districts: {merged_df_final[merge_district_col].nunique()}\")\n",
        "print(f\"  - Date range: {merged_df_final[merge_date_col].min()} to {merged_df_final[merge_date_col].max()}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
