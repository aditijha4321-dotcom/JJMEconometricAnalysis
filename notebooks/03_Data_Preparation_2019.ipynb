{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Preparation 2019: Merge Synthetic Water Data with Real Health Data\n",
        "\n",
        "This notebook merges the synthetic JJM FHTC coverage data with the real health data for the 2019-2020 baseline period.\n",
        "\n",
        "**Objectives:**\n",
        "1. Load synthetic water data (jjm_raw_2019.csv)\n",
        "2. Load real health data (health_2019_cleaned.csv) and filter for \"Inpatient\" indicators\n",
        "3. Clean and standardize data (numeric types, district name matching)\n",
        "4. Merge datasets on District_Name and Month\n",
        "5. Save the final merged panel dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import difflib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add parent directory to path for config imports\n",
        "sys.path.insert(0, str(Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()))\n",
        "\n",
        "try:\n",
        "    from config import FILE_PATHS\n",
        "    print(\"✓ Config imported successfully\")\n",
        "except ImportError:\n",
        "    # Fallback paths if config not available\n",
        "    FILE_PATHS = {\n",
        "        \"data\": {\n",
        "            \"raw\": \"data/raw\",\n",
        "            \"processed\": \"data/processed\"\n",
        "        }\n",
        "    }\n",
        "    print(\"⚠ Using fallback paths\")\n",
        "\n",
        "print(\"✓ Libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load synthetic JJM data (Water Data)\n",
        "jjm_file = Path(FILE_PATHS[\"data\"][\"raw\"]) / \"jjm_raw_2019.csv\"\n",
        "print(f\"Loading synthetic JJM data from: {jjm_file}\")\n",
        "\n",
        "try:\n",
        "    jjm_df = pd.read_csv(jjm_file, parse_dates=['Date'])\n",
        "    print(f\"✓ JJM data loaded: {jjm_df.shape[0]:,} rows, {jjm_df.shape[1]} columns\")\n",
        "    print(f\"  Columns: {list(jjm_df.columns)}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    display(jjm_df.head())\n",
        "except FileNotFoundError:\n",
        "    print(f\"❌ Error: File not found at {jjm_file}\")\n",
        "    print(\"Please run src/generate_synthetic_jjm.py first to generate the data\")\n",
        "    jjm_df = None\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error loading JJM data: {e}\")\n",
        "    jjm_df = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load Health Data\n",
        "health_file = Path(FILE_PATHS[\"data\"][\"processed\"]) / \"health_2019_cleaned.csv\"\n",
        "print(f\"\\nLoading health data from: {health_file}\")\n",
        "\n",
        "try:\n",
        "    health_df = pd.read_csv(health_file)\n",
        "    print(f\"✓ Health data loaded: {health_df.shape[0]:,} rows, {health_df.shape[1]} columns\")\n",
        "    print(f\"  Columns: {list(health_df.columns)}\")\n",
        "    print(f\"\\nFirst few rows:\")\n",
        "    display(health_df.head())\n",
        "except FileNotFoundError:\n",
        "    print(f\"❌ Error: File not found at {health_file}\")\n",
        "    print(\"Please run src/process_health_2019_final.py first to generate the data\")\n",
        "    health_df = None\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error loading health data: {e}\")\n",
        "    health_df = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Health Data Filter: Keep ONLY rows where Indicator contains \"Inpatient\" (case-insensitive)\n",
        "if health_df is not None:\n",
        "    print(f\"\\nFiltering health data for 'Inpatient' indicators...\")\n",
        "    print(f\"  Original rows: {len(health_df):,}\")\n",
        "    \n",
        "    if 'Indicator' in health_df.columns:\n",
        "        # Filter for rows where Indicator contains \"Inpatient\" (case-insensitive)\n",
        "        health_df_filtered = health_df[\n",
        "            health_df['Indicator'].astype(str).str.lower().str.contains('inpatient', na=False)\n",
        "        ].copy()\n",
        "        \n",
        "        print(f\"  Filtered rows: {len(health_df_filtered):,}\")\n",
        "        print(f\"  Rows removed: {len(health_df) - len(health_df_filtered):,}\")\n",
        "        \n",
        "        if len(health_df_filtered) > 0:\n",
        "            print(f\"\\n  Sample filtered data:\")\n",
        "            display(health_df_filtered.head())\n",
        "        else:\n",
        "            print(f\"  ⚠ Warning: No rows found with 'Inpatient' in Indicator column\")\n",
        "            health_df_filtered = None\n",
        "    else:\n",
        "        print(f\"  ❌ Error: 'Indicator' column not found in health data\")\n",
        "        health_df_filtered = None\n",
        "else:\n",
        "    health_df_filtered = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Step 2: Clean & Standardize\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Water Data: Ensure FHTC_Coverage is numeric\n",
        "if jjm_df is not None:\n",
        "    print(\"Cleaning Water Data...\")\n",
        "    jjm_df_clean = jjm_df.copy()\n",
        "    \n",
        "    # Ensure FHTC_Coverage is numeric\n",
        "    if 'FHTC_Coverage' in jjm_df_clean.columns:\n",
        "        jjm_df_clean['FHTC_Coverage'] = pd.to_numeric(jjm_df_clean['FHTC_Coverage'], errors='coerce')\n",
        "        print(f\"  ✓ FHTC_Coverage converted to numeric\")\n",
        "        print(f\"  Missing values: {jjm_df_clean['FHTC_Coverage'].isnull().sum()}\")\n",
        "    else:\n",
        "        print(f\"  ⚠ Warning: FHTC_Coverage column not found\")\n",
        "    \n",
        "    # Create Month column from Date if needed\n",
        "    if 'Date' in jjm_df_clean.columns and 'Month' not in jjm_df_clean.columns:\n",
        "        jjm_df_clean['Month'] = jjm_df_clean['Date'].dt.strftime('%B')\n",
        "        print(f\"  ✓ Created Month column from Date\")\n",
        "    \n",
        "    print(f\"  Final shape: {jjm_df_clean.shape}\")\n",
        "else:\n",
        "    jjm_df_clean = None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Health Data: Ensure Cases is numeric\n",
        "if health_df_filtered is not None:\n",
        "    print(\"\\nCleaning Health Data...\")\n",
        "    health_df_clean = health_df_filtered.copy()\n",
        "    \n",
        "    # Ensure Cases is numeric\n",
        "    if 'Cases' in health_df_clean.columns:\n",
        "        health_df_clean['Cases'] = pd.to_numeric(health_df_clean['Cases'], errors='coerce')\n",
        "        print(f\"  ✓ Cases converted to numeric\")\n",
        "        print(f\"  Missing values: {health_df_clean['Cases'].isnull().sum()}\")\n",
        "    else:\n",
        "        print(f\"  ⚠ Warning: Cases column not found\")\n",
        "    \n",
        "    print(f\"  Final shape: {health_df_clean.shape}\")\n",
        "else:\n",
        "    health_df_clean = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# District Names: Use difflib (fuzzy matching) to create a dictionary mapping Health District names to Water District names\n",
        "if jjm_df_clean is not None and health_df_clean is not None:\n",
        "    print(\"\\nCreating district name mapping using fuzzy matching...\")\n",
        "    \n",
        "    # Get unique district names from both datasets\n",
        "    water_districts = sorted(jjm_df_clean['District_Name'].dropna().unique())\n",
        "    health_districts = sorted(health_df_clean['District_Name'].dropna().unique())\n",
        "    \n",
        "    print(f\"  Water districts: {len(water_districts)}\")\n",
        "    print(f\"  Health districts: {len(health_districts)}\")\n",
        "    \n",
        "    # Create mapping dictionary using fuzzy matching\n",
        "    district_mapping = {}\n",
        "    unmatched_health = []\n",
        "    \n",
        "    for health_district in health_districts:\n",
        "        # Find the best match in water districts\n",
        "        matches = difflib.get_close_matches(\n",
        "            health_district, \n",
        "            water_districts, \n",
        "            n=1, \n",
        "            cutoff=0.6  # Minimum similarity threshold\n",
        "        )\n",
        "        \n",
        "        if matches:\n",
        "            district_mapping[health_district] = matches[0]\n",
        "        else:\n",
        "            unmatched_health.append(health_district)\n",
        "            # If no good match, keep original name\n",
        "            district_mapping[health_district] = health_district\n",
        "    \n",
        "    print(f\"  ✓ Created mapping for {len(district_mapping)} districts\")\n",
        "    if unmatched_health:\n",
        "        print(f\"  ⚠ {len(unmatched_health)} districts could not be matched (keeping original names)\")\n",
        "        print(f\"    Sample unmatched: {unmatched_health[:5]}\")\n",
        "    \n",
        "    # Apply mapping to Health dataframe\n",
        "    health_df_clean['District_Name'] = health_df_clean['District_Name'].map(district_mapping).fillna(health_df_clean['District_Name'])\n",
        "    print(f\"  ✓ Applied mapping to health data\")\n",
        "    \n",
        "    # Show sample mappings\n",
        "    print(f\"\\n  Sample mappings:\")\n",
        "    sample_mappings = list(district_mapping.items())[:10]\n",
        "    for orig, mapped in sample_mappings:\n",
        "        if orig != mapped:\n",
        "            print(f\"    '{orig}' → '{mapped}'\")\n",
        "else:\n",
        "    print(\"\\n⚠ Cannot create district mapping: One or both datasets are missing\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Step 3: Merge\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Merge the two dataframes on ['District_Name', 'Month'] using Inner Join\n",
        "if jjm_df_clean is not None and health_df_clean is not None:\n",
        "    print(\"Merging datasets...\")\n",
        "    print(f\"  Water data shape: {jjm_df_clean.shape}\")\n",
        "    print(f\"  Health data shape: {health_df_clean.shape}\")\n",
        "    \n",
        "    # Check if required columns exist\n",
        "    required_cols_jjm = ['District_Name', 'Month']\n",
        "    required_cols_health = ['District_Name', 'Month']\n",
        "    \n",
        "    if all(col in jjm_df_clean.columns for col in required_cols_jjm) and \\\n",
        "       all(col in health_df_clean.columns for col in required_cols_health):\n",
        "        \n",
        "        # Perform inner join on District_Name and Month\n",
        "        merged_df = pd.merge(\n",
        "            jjm_df_clean,\n",
        "            health_df_clean,\n",
        "            on=['District_Name', 'Month'],\n",
        "            how='inner',\n",
        "            suffixes=('_water', '_health')\n",
        "        )\n",
        "        \n",
        "        print(f\"  ✓ Merge completed\")\n",
        "        print(f\"  Merged data shape: {merged_df.shape}\")\n",
        "        print(f\"  Columns: {list(merged_df.columns)}\")\n",
        "        \n",
        "        # Show first few rows\n",
        "        print(f\"\\n  First 5 rows:\")\n",
        "        display(merged_df.head(5))\n",
        "        \n",
        "    else:\n",
        "        print(f\"  ❌ Error: Required columns for merging not found\")\n",
        "        print(f\"    Water data columns: {list(jjm_df_clean.columns)}\")\n",
        "        print(f\"    Health data columns: {list(health_df_clean.columns)}\")\n",
        "        merged_df = None\n",
        "else:\n",
        "    print(\"❌ Cannot merge: One or both datasets are missing\")\n",
        "    merged_df = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Step 4: Save\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Save the result to data/processed/final_panel_2019.csv\n",
        "if merged_df is not None:\n",
        "    output_file = Path(FILE_PATHS[\"data\"][\"processed\"]) / \"final_panel_2019.csv\"\n",
        "    output_file.parent.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    merged_df.to_csv(output_file, index=False, encoding='utf-8')\n",
        "    \n",
        "    print(f\"✓ Saved merged data to: {output_file}\")\n",
        "    print(f\"\\nFinal DataFrame Shape: {merged_df.shape}\")\n",
        "    print(f\"  Rows: {merged_df.shape[0]:,}\")\n",
        "    print(f\"  Columns: {merged_df.shape[1]}\")\n",
        "    print(f\"\\nFirst 5 rows:\")\n",
        "    display(merged_df.head(5))\n",
        "else:\n",
        "    print(\"❌ Cannot save: Merged dataset is missing\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "The merged panel dataset has been created and saved to `data/processed/final_panel_2019.csv`.\n",
        "\n",
        "**Dataset contains:**\n",
        "- Synthetic water coverage data (FHTC_Coverage) merged with real health data (Cases)\n",
        "- Filtered to include only \"Inpatient\" indicators\n",
        "- District names standardized using fuzzy matching\n",
        "- Merged on District_Name and Month using inner join\n",
        "\n",
        "**Next Steps:**\n",
        "- Use this dataset for econometric analysis\n",
        "- Detect self-reporting bias in water coverage data\n",
        "- Analyze the relationship between water coverage and health outcomes\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
